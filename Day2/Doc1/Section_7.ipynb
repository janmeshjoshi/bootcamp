{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  Profiling and Timing",
   "id": "e51a1961000310f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import timeit\n",
    "import time\n",
    "import cProfile\n",
    "import random\n",
    "from memory_profiler import profile\n",
    "\n",
    "# 1. timeit basic usage\n",
    "time_taken = timeit.timeit('sum(range(10000))', number=1000)\n",
    "print(f\"Time taken: {time_taken:.4f} seconds\")\n",
    "\n",
    "# 2. List vs Generator comparison\n",
    "list_time = timeit.timeit('[x*x for x in range(1000000)]', number=10)\n",
    "gen_time = timeit.timeit('(x*x for x in range(1000000))', number=10)\n",
    "print(f\"List comprehension: {list_time:.4f}s, Generator: {gen_time:.4f}s\")\n",
    "\n",
    "# 3. cProfile usage (will show output when run)\n",
    "def profile_me():\n",
    "    total = 0\n",
    "    for i in range(10000):\n",
    "        total += i*i\n",
    "    return total\n",
    "\n",
    "cProfile.run('profile_me()')\n",
    "\n",
    "# 4. line_profiler example (requires separate installation)\n",
    "@profile\n",
    "def memory_intensive():\n",
    "    data = [random.random() for _ in range(100000)]\n",
    "    result = [x * 2 for x in data]\n",
    "    return sum(result)\n",
    "\n",
    "# 5. Manual timing\n",
    "start = time.time()\n",
    "sum(range(1000000))\n",
    "end = time.time()\n",
    "print(f\"Manual timing: {end - start:.4f} seconds\")\n",
    "\n",
    "# 6. Benchmark sorting\n",
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n-i-1):\n",
    "            if arr[j] > arr[j+1]:\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
    "\n",
    "data = [random.randint(0, 1000) for _ in range(1000)]\n",
    "sorted_time = timeit.timeit('sorted(data)', globals=globals(), number=100)\n",
    "bubble_time = timeit.timeit('bubble_sort(data.copy())', globals=globals(), number=100)\n",
    "print(f\"Built-in sorted: {sorted_time:.4f}s, Bubble sort: {bubble_time:.4f}s\")\n",
    "\n",
    "# 7. memory_profiler usage\n",
    "@profile\n",
    "def create_large_list():\n",
    "    return [i**2 for i in range(100000)]\n",
    "\n",
    "large_list = create_large_list()"
   ],
   "id": "fa7ef93ad39d4c81"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Lazy Evaluation and Efficiency\n",
   "id": "4ac4aae9fc64bb33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import itertools\n",
    "\n",
    "# 1. Large file reading with generator\n",
    "def read_large_file(filename):\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            yield line.strip()\n",
    "\n",
    "# 2. Memory comparison\n",
    "numbers = range(1000000)\n",
    "list_size = sys.getsizeof([x for x in numbers])\n",
    "gen_size = sys.getsizeof(x for x in numbers)\n",
    "print(f\"List size: {list_size:,} bytes, Generator size: {gen_size:,} bytes\")\n",
    "\n",
    "# 3. Lazy CSV filter\n",
    "def filter_csv(filename, condition):\n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        yield header\n",
    "        for row in reader:\n",
    "            if condition(row):\n",
    "                yield row\n",
    "\n",
    "# 4. Short-circuiting with any()\n",
    "big_list = range(100000000)\n",
    "divisible_by_99 = any(x % 99 == 0 for x in big_list)\n",
    "print(f\"Contains divisible by 99: {divisible_by_99}\")\n",
    "\n",
    "# 5. itertools.islice example\n",
    "first_10_lines = itertools.islice(read_large_file('bigfile.txt'), 10)\n",
    "print(list(first_10_lines))\n",
    "\n",
    "# 6. Avoid temporary lists\n",
    "total = sum(x for x in range(1000000))\n",
    "print(f\"Sum: {total}\")\n",
    "\n",
    "# 7. Streaming file copy\n",
    "def stream_copy(source, dest):\n",
    "    with open(source) as src, open(dest, 'w') as dst:\n",
    "        for line in src:\n",
    "            dst.write(line)\n",
    "\n",
    "# 8. Yield vs return\n",
    "def get_numbers_list(n):\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(i * 2)\n",
    "    return result\n",
    "\n",
    "def get_numbers_gen(n):\n",
    "    for i in range(n):\n",
    "        yield i * 2\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample files\n",
    "    with open('bigfile.txt', 'w') as f:\n",
    "        f.writelines(f\"Line {i}\\n\" for i in range(1000))\n",
    "\n",
    "    with open('data.csv', 'w') as f:\n",
    "        f.write(\"id,name,value\\n\")\n",
    "        f.writelines(f\"{i},Item{i},{i*10}\\n\" for i in range(100))\n",
    "\n",
    "    # Test the generators\n",
    "    print(\"First 5 lines:\")\n",
    "    for i, line in enumerate(read_large_file('bigfile.txt')):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        print(line)\n",
    "\n",
    "    print(\"\\nFiltered CSV (value > 50):\")\n",
    "    filtered = filter_csv('data.csv', lambda row: int(row[2]) > 50)\n",
    "    for row in itertools.islice(filtered, 5):\n",
    "        print(row)\n",
    "\n",
    "    # Memory comparison\n",
    "    list_nums = get_numbers_list(1000000)\n",
    "    gen_nums = get_numbers_gen(1000000)\n",
    "    print(f\"\\nList memory: {sys.getsizeof(list_nums):,} bytes\")\n",
    "    print(f\"Generator memory: {sys.getsizeof(gen_nums):,} bytes\")"
   ],
   "id": "1dee7393ce63f09d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Debugging Tools and Practices",
   "id": "c8034571597088d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pdb\n",
    "import traceback\n",
    "import logging\n",
    "import warnings\n",
    "from functools import wraps\n",
    "\n",
    "# Configure structured logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 1. pdb.set_trace()\n",
    "def debug_function(x):\n",
    "    y = x * 2\n",
    "    pdb.set_trace()  # Execution pauses here\n",
    "    return y + 3\n",
    "\n",
    "# 2. breakpoint() (Python 3.7+)\n",
    "def calculate_stats(data):\n",
    "    total = sum(data)\n",
    "    breakpoint()  # Modern equivalent of pdb.set_trace()\n",
    "    return total / len(data)\n",
    "\n",
    "# 3. traceback module\n",
    "def risky_operation():\n",
    "    try:\n",
    "        1 / 0\n",
    "    except Exception:\n",
    "        print(\"Error details:\\n\", traceback.format_exc())\n",
    "\n",
    "# 4. Structured logging decorator\n",
    "def log_calls(func):\n",
    "    @wraps(func\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logger.debug(f\"Entering {func.__name__}\")\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            logger.debug(f\"Exiting {func.__name__}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Exception in {func.__name__}: {e}\")\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "# 5. warnings module\n",
    "def deprecated_feature():\n",
    "    warnings.warn(\"This feature will be removed\", DeprecationWarning)\n",
    "    return \"old result\"\n",
    "\n",
    "# 6. Verbose exceptions\n",
    "def parse_number(s):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception as e:\n",
    "        print(f\"Error type: {type(e).__name__}, Message: {e}\")\n",
    "        return None\n",
    "\n",
    "# 7. Debug recursive calls\n",
    "def factorial(n, level=0):\n",
    "    logger.debug(f\"{'  '*level}Calling factorial({n})\")\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return n * factorial(n-1, level+1)\n",
    "\n",
    "# 8. Fail loud after logging\n",
    "def critical_operation():\n",
    "    try:\n",
    "        # Simulate error\n",
    "        raise ValueError(\"Critical data missing\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Operation failed\")\n",
    "        raise  # Re-raise after logging\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    debug_function(5)  # Will pause in pdb\n",
    "    calculate_stats([1,2,3])  # Will pause at breakpoint\n",
    "    risky_operation()\n",
    "    deprecated_feature()\n",
    "    parse_number(\"abc\")\n",
    "    factorial(5)\n",
    "\n",
    "    try:\n",
    "        critical_operation()\n",
    "    except ValueError:\n",
    "        print(\"Handled the critical error\")"
   ],
   "id": "98e5fbee86cf8ee9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Design for Observability",
   "id": "a1ec5481fc064538"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import logging\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "from functools import wraps\n",
    "from random import random\n",
    "\n",
    "# Configuration\n",
    "DEBUG = os.getenv('DEBUG', 'False').lower() == 'true'\n",
    "logging.basicConfig(level=logging.DEBUG if DEBUG else logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Metrics dictionary\n",
    "metrics = {\n",
    "    'calls': {},\n",
    "    'timers': {},\n",
    "    'counters': {},\n",
    "    'errors': {}\n",
    "}\n",
    "\n",
    "def log_with_context(user_id=None):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start_time = time.time()\n",
    "            extra = {'user_id': user_id, 'func': func.__name__}\n",
    "\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                duration = time.time() - start_time\n",
    "\n",
    "                metrics['calls'][func.__name__] = metrics['calls'].get(func.__name__, 0) + 1\n",
    "                metrics['timers'][func.__name__] = metrics['timers'].get(func.__name__, 0) + duration\n",
    "\n",
    "                logger.info(f\"Completed {func.__name__} in {duration:.4f}s\", extra=extra)\n",
    "                return result\n",
    "\n",
    "            except Exception as e:\n",
    "                error_id = f\"ERR-{int(random()*10000):04d}\"\n",
    "                metrics['errors'][error_id] = metrics['errors'].get(error_id, 0) + 1\n",
    "                logger.error(f\"Error {error_id} in {func.__name__}: {str(e)}\", extra=extra)\n",
    "                raise\n",
    "\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@log_with_context(user_id=\"user123\")\n",
    "def process_data(data):\n",
    "    \"\"\"Example function with logging and timing\"\"\"\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    if random() > 0.8:\n",
    "        raise ValueError(\"Random processing error\")\n",
    "    return data * 2\n",
    "\n",
    "def health_check():\n",
    "    \"\"\"System health check\"\"\"\n",
    "    status = {\n",
    "        'memory': psutil.virtual_memory().percent,\n",
    "        'cpu': psutil.cpu_percent(),\n",
    "        'load': os.getloadavg(),\n",
    "        'disk': psutil.disk_usage('/').percent\n",
    "    }\n",
    "    logger.info(\"System status\", extra={'status': status})\n",
    "    return status\n",
    "\n",
    "def get_metrics():\n",
    "    \"\"\"Return collected metrics\"\"\"\n",
    "    return metrics\n",
    "\n",
    "def print_resource_usage():\n",
    "    \"\"\"Print current resource usage\"\"\"\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"Memory: {mem.used/1024/1024:.1f}MB used ({mem.percent}%)\")\n",
    "    print(f\"CPU: {psutil.cpu_percent()}%\")\n",
    "    print(f\"Load: {os.getloadavg()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            result = process_data(i)\n",
    "            print(f\"Result: {result}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Failed: {e}\")\n",
    "\n",
    "    # System checks\n",
    "    health_status = health_check()\n",
    "    print(\"\\nHealth check:\", health_status)\n",
    "\n",
    "    # Metrics\n",
    "    print(\"\\nMetrics:\")\n",
    "    for k, v in get_metrics().items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    # Current resources\n",
    "    print(\"\\nCurrent resources:\")\n",
    "    print_resource_usage()"
   ],
   "id": "b7e40d5f40d352ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
